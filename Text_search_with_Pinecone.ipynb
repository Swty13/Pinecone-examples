{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Similarity \n",
    "\n",
    "> In this notebook I am discussing about how we made embedding from a Transformer model,upserting embedding in Pinecone system and Query most similar question from the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Connect to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_pinecone():\n",
    "    \"\"\"\n",
    "    To use Pinecone, one must have an API key.\n",
    "    By default, ENVIRONMENT is us-west1-gcp.\n",
    "    :return:None\n",
    "    \"\"\"\n",
    "    PINECONE_API_KEY = \"0b0f6a93-7723-49bf-a006-aec1b05c81d2\"\n",
    "    pinecone.init(api_key=PINECONE_API_KEY, environment=\"us-west1-gcp-free\")\n",
    "\n",
    "\n",
    "def connect_pinecone_index(pinecone_index_name):\n",
    "    \"\"\"\n",
    "    Connection to the pinecone index\n",
    "    :param pinecone_index_name\n",
    "    :return: pinecone index\n",
    "    \"\"\"\n",
    "    initialize_pinecone()\n",
    "    pinecone_index = pinecone.Index(index_name=pinecone_index_name)\n",
    "    return pinecone_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Name should be in small case letter\n",
    "### Dimension can be changed according the embedding size\n",
    "### Metric can be change according to the use case\n",
    "initialize_pinecone()\n",
    "pinecone_index_name = \"pinecone-examples\"\n",
    "pinecone.create_index(pinecone_index_name, index_type=\"approximated\", dimension=768, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Connect to DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = connect_pinecone_index(pinecone_index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(features: {'questions': Sequence(feature={'id': Value(dtype='int32', id=None), 'text': Value(dtype='string', id=None)}, length=-1, id=None), 'is_duplicate': Value(dtype='bool', id=None)}, num_rows: 404290)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('quora', split='train')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Can we drop some devices playing videos in North Sentinel and try to teach the people living there?\n",
      "What are the reviews of the OnePlus 2?\n",
      "What are some tips on making it through the job interview process at National Interstate?\n",
      "Is it predicted by the Qur'an that Hillary Clinton will become the President of the USA? They say that the Qur'an has the answer to everything.\n",
      "537362\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "\n",
    "for record in dataset['questions']:\n",
    "    questions.extend(record['text'])\n",
    "  \n",
    "# remove duplicates\n",
    "questions = list(set(questions))\n",
    "print('\\n'.join(questions[:5]))\n",
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=[]\n",
    "for record in dataset['questions']:\n",
    "    ids.extend(record['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import tensorflow.compat.v1 as tf\n",
    "from torch.quantization import quantize_dynamic\n",
    "from torch.nn import Embedding, Linear\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Transformer Model\n",
    "model=SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Embedding on Sample of 100 Data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(ids,text,count):   \n",
    "    data_id =[str(i) for i in ids[1:count+1]]\n",
    "    data=text[1:count+1]\n",
    "    metadata = [{'text': text} for text in data]\n",
    "    embedding = model.encode(data,show_progress_bar=True,\n",
    "                                convert_to_tensor=False,\n",
    "                                convert_to_numpy=True,\n",
    "                                batch_size=32,\n",
    "                          )\n",
    "    \n",
    "    vectors = list(zip(data_id, embedding.tolist(),metadata))\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d465b807cb40eabb17bee52cdc7768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedded_vectors=generate_embeddings(ids,questions,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Insert the data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data Format : \n",
    "\n",
    "index.upsert([\n",
    "    (\"A\", [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]),\n",
    "    (\"B\", [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]),\n",
    "    (\"C\", [0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3]),\n",
    "    (\"D\", [0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4]),\n",
    "    (\"E\", [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Query Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '3',\n",
       "              'metadata': {'text': 'What are the reviews of the OnePlus 2?'},\n",
       "              'score': 0.756250858,\n",
       "              'values': []}],\n",
       " 'namespace': 'text-search'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are reviews of Oneplus phone?\"\n",
    "\n",
    "# create the query vector\n",
    "xq = model.encode(query).tolist()\n",
    "\n",
    "# now query\n",
    "xc = index.query(xq, top_k=1, include_metadata=True,namespace=\"text-search\")\n",
    "xc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Returned Text share the exact same meaning as our question, or are related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Delete Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.delete_index(pinecone_index_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_env_mounted",
   "language": "python",
   "name": "mlflow_env_mounted"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
